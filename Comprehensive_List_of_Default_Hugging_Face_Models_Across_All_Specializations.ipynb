{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Comprehensive List of **Default Hugging Face Models** Across All Specializations\n",
        "\n",
        "Below is a fully structured, clean, and mathematically formatted Markdown version of the complete taxonomy of **default / canonical Hugging Face models** across all tasks and domains.\n",
        "\n",
        "---\n",
        "\n",
        "# **1. Foundation Language Models (LLMs) — Decoder-Only (GPT-Like)**\n",
        "\n",
        "These are Hugging Face’s default **causal language models** for text generation.\n",
        "\n",
        "- GPT-2 (baseline default)\n",
        "- GPT-Neo / GPT-NeoX  \n",
        "- GPT-J  \n",
        "- OPT  \n",
        "- BLOOM  \n",
        "- Falcon  \n",
        "- MPT  \n",
        "- LLaMA / LLaMA-2 / LLaMA-3  \n",
        "- Qwen / Qwen-2  \n",
        "- Mixtral / Mistral  \n",
        "- Phi-2 / Phi-3  \n",
        "- StarCoder / StarCoder2  \n",
        "- CodeGen  \n",
        "- DeepSeek-Coder  \n",
        "- Yi / Yi-Coder  \n",
        "- Gemma  \n",
        "- XGen  \n",
        "\n",
        "**Default pipeline tasks:**  \n",
        "`text-generation`, `text2text-generation`, `fill-mask`, `causal-lm`.\n",
        "\n",
        "---\n",
        "\n",
        "# **2. Encoder-Only Models (BERT-Like)**\n",
        "\n",
        "These models are defaults for embeddings and token-level tasks.\n",
        "\n",
        "- BERT (base, large)  \n",
        "- RoBERTa  \n",
        "- DistilBERT  \n",
        "- ALBERT  \n",
        "- XLNet  \n",
        "- Electra  \n",
        "- CamemBERT  \n",
        "- mBERT (BERT-base-multilingual-cased)  \n",
        "- XLM-R  \n",
        "\n",
        "**Default pipeline tasks:**  \n",
        "`feature-extraction`, `text-classification`, `token-classification`.\n",
        "\n",
        "---\n",
        "\n",
        "# **3. Encoder–Decoder Models (Seq2Seq, T5-Family)**\n",
        "\n",
        "Used for summarization, translation, and general text-to-text tasks.\n",
        "\n",
        "- T5  \n",
        "- FLAN-T5  \n",
        "- mT5  \n",
        "- BART  \n",
        "- MarianMT (default translation family)  \n",
        "- Pegasus (default summarization)  \n",
        "- LongT5  \n",
        "- LED (LongformerEncoderDecoder)\n",
        "\n",
        "**Default pipeline tasks:**  \n",
        "`summarization`, `translation`, `text2text-generation`.\n",
        "\n",
        "---\n",
        "\n",
        "# **4. Default Sentence Embedding Models**\n",
        "\n",
        "- `sentence-transformers/all-MiniLM-L6-v2`  \n",
        "- `sentence-transformers/mpnet-base-v2`  \n",
        "- `sentence-transformers/all-mpnet-base-v2`  \n",
        "- gte-base / gte-large  \n",
        "- e5-small / e5-large / e5-mistral  \n",
        "- Instructor-XL / Instructor-Large  \n",
        "\n",
        "**Default pipeline task:**  \n",
        "`feature-extraction` (RAG embeddings).\n",
        "\n",
        "---\n",
        "\n",
        "# **5. Computer Vision — Default HF Models**\n",
        "\n",
        "## **Image Classification**\n",
        "- ResNet (18, 34, 50)  \n",
        "- ViT (Vision Transformer — HF’s default transformer for CV)  \n",
        "- ConvNeXt  \n",
        "- EfficientNet  \n",
        "- MobileNet V2 / V3  \n",
        "- Swin Transformer  \n",
        "- BEiT  \n",
        "- DeiT  \n",
        "\n",
        "## **Object Detection**\n",
        "- DETR  \n",
        "- DINO / DINOv2  \n",
        "- YOLOS  \n",
        "- RT-DETR  \n",
        "- GroundingDINO  \n",
        "\n",
        "## **Segmentation**\n",
        "- SegFormer  \n",
        "- MaskFormer  \n",
        "- UPerNet  \n",
        "- SAM / MobileSAM / FastSAM  \n",
        "\n",
        "## **Image-to-Image**\n",
        "- ControlNet  \n",
        "- Stable Diffusion Img2Img  \n",
        "\n",
        "## **Vision-Language**\n",
        "- CLIP  \n",
        "- BLIP / BLIP-2  \n",
        "- OWL-ViT  \n",
        "\n",
        "**Default pipeline tasks:**  \n",
        "`image-classification`, `object-detection`, `image-segmentation`, `zero-shot-image-classification`.\n",
        "\n",
        "---\n",
        "\n",
        "# **6. Audio & Speech Models (Hugging Face Defaults)**\n",
        "\n",
        "## **ASR (Speech-to-Text)**\n",
        "- Whisper (tiny → large-v3)  \n",
        "- Wav2Vec2  \n",
        "- HuBERT  \n",
        "- MMS  \n",
        "\n",
        "## **Speaker Diarization**\n",
        "- `pyannote/speaker-diarization-3.1` (default)\n",
        "\n",
        "## **Text-to-Speech**\n",
        "- SpeechT5  \n",
        "- FastSpeech2  \n",
        "- VITS / YourTTS  \n",
        "\n",
        "## **Audio Classification**\n",
        "- AST  \n",
        "- Wav2Vec2-CTC  \n",
        "\n",
        "---\n",
        "\n",
        "# **7. Multimodal & Vision-Language Models**\n",
        "\n",
        "Default HF multimodal models:\n",
        "\n",
        "- CLIP  \n",
        "- BLIP / BLIP-2  \n",
        "- Flamingo / OpenFlamingo  \n",
        "- LLaVA / LLaVA-1.5 / LLaVA-NeXT  \n",
        "- MiniGPT-4  \n",
        "- Qwen-VL / Qwen2-VL  \n",
        "- Kosmos-2  \n",
        "- Pix2Struct  \n",
        "- Donut (OCR)  \n",
        "- LayoutLM / LayoutLMv3  \n",
        "- Mistral-VL, Yi-VL  \n",
        "\n",
        "**Default pipeline tasks:**  \n",
        "`image-to-text`, `document-question-answering`, `visual-question-answering`.\n",
        "\n",
        "---\n",
        "\n",
        "# **8. Diffusion Models (Text-to-Image Standards)**\n",
        "\n",
        "## **Stable Diffusion Family**\n",
        "- SD 1.4 / 1.5  \n",
        "- SD 2.0 / 2.1  \n",
        "- SDXL  \n",
        "- Stable Diffusion Turbo  \n",
        "- SDXL-Lightning  \n",
        "- DreamBooth fine-tuned variants  \n",
        "\n",
        "## **Latent Diffusion**\n",
        "- LDM text2img  \n",
        "- LDM img2img  \n",
        "\n",
        "## **Other Generative Families**\n",
        "- Consistency Models  \n",
        "- ControlNet  \n",
        "- PixArt-α / PixArt-Sigma  \n",
        "- DeepFloyd IF  \n",
        "- Kandinsky 2.2  \n",
        "\n",
        "---\n",
        "\n",
        "# **9. Reinforcement Learning Models**\n",
        "\n",
        "- Decision Transformer  \n",
        "- Trajectory Transformer  \n",
        "- GTrXL  \n",
        "\n",
        "Plus Hugging Face TRL methods:\n",
        "- PPO  \n",
        "- DPO  \n",
        "- Reinforce  \n",
        "- Reward Models  \n",
        "\n",
        "---\n",
        "\n",
        "# **10. Time Series Forecasting Models**\n",
        "\n",
        "- N-BEATS  \n",
        "- TFT  \n",
        "- TCN  \n",
        "- Amazon Chronos  \n",
        "- TimesFM  \n",
        "- PatchTST  \n",
        "- Informer / Autoformer  \n",
        "- ETSformer  \n",
        "\n",
        "---\n",
        "\n",
        "# **11. Hugging Face Tokenizers (Standard)**\n",
        "\n",
        "- BPE  \n",
        "- WordPiece  \n",
        "- SentencePiece  \n",
        "- Unigram LM  \n",
        "- GPT-2 BPE  \n",
        "\n",
        "---\n",
        "\n",
        "# **12. Default HF Pipeline Models (Canonical Table)**\n",
        "\n",
        "| Task | Default Model |\n",
        "|------|---------------|\n",
        "| text-generation | gpt2 |\n",
        "| text-classification | distilbert-base-uncased-finetuned-sst-2-english |\n",
        "| zero-shot-classification | facebook/bart-large-mnli |\n",
        "| fill-mask | bert-base-uncased |\n",
        "| translation | Helsinki-NLP/opus-mt-* |\n",
        "| summarization | facebook/bart-large-cnn |\n",
        "| question-answering | distilbert-base-cased-distilled-squad |\n",
        "| ner | dbmdz/bert-large-cased-finetuned-conll03-english |\n",
        "| image-classification | google/vit-base-patch16-224 |\n",
        "| object-detection | facebook/detr-resnet-50 |\n",
        "| speech-to-text | openai/whisper-small |\n",
        "| audio-classification | superb/hubert-base-superb-ks |\n",
        "| image-to-text | nlpconnect/vit-gpt2-image-captioning |\n",
        "| document-qa | impira/layoutlm-document-qa |\n",
        "| image-segmentation | facebook/mask2former-swin-base-coco |\n",
        "\n",
        "---\n",
        "\n",
        "# **13. Final Condensed “Canonical” HF Models by Field**\n",
        "\n",
        "## **NLP**\n",
        "- BERT  \n",
        "- RoBERTa  \n",
        "- DistilBERT  \n",
        "- ALBERT  \n",
        "- XLNet  \n",
        "- Electra  \n",
        "- GPT-2  \n",
        "- T5  \n",
        "- BART  \n",
        "- MarianMT  \n",
        "- Pegasus  \n",
        "- XLM-R  \n",
        "- mT5  \n",
        "- FLAN-T5  \n",
        "\n",
        "## **LLMs**\n",
        "- LLaMA  \n",
        "- Falcon  \n",
        "- Mistral  \n",
        "- Qwen  \n",
        "- Gemma  \n",
        "- Mixtral  \n",
        "- StarCoder  \n",
        "- Phi  \n",
        "\n",
        "## **Vision**\n",
        "- ViT  \n",
        "- ResNet  \n",
        "- ConvNeXt  \n",
        "- Swin  \n",
        "- BEiT  \n",
        "- DETR  \n",
        "- SegFormer  \n",
        "- SAM  \n",
        "- CLIP  \n",
        "\n",
        "## **Audio**\n",
        "- Whisper  \n",
        "- Wav2Vec2  \n",
        "- HuBERT  \n",
        "- MMS  \n",
        "\n",
        "## **Multimodal**\n",
        "- CLIP  \n",
        "- BLIP / BLIP-2  \n",
        "- Flamingo  \n",
        "- LLaVA  \n",
        "- Pix2Struct  \n",
        "- Donut  \n",
        "- LayoutLM  \n",
        "\n",
        "## **Diffusion**\n",
        "- Stable Diffusion (all versions)  \n",
        "- SDXL  \n",
        "- DeepFloyd IF  \n",
        "- Kandinsky  \n",
        "- PixArt  \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MGbcNQZTGFBw"
      }
    }
  ]
}