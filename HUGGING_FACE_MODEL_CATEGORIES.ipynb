{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HUGGING FACE MODEL CATEGORIES (Complete Map)\n",
        "\n",
        "Below is the master list of all model categories officially supported and indexed on the Hugging Face Hub.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Large Language Models (LLMs)\n",
        "\n",
        "Foundation models for text generation and chat.\n",
        "\n",
        "- LLaMA / Llama-2 / Llama-3 / Llama-3.1  \n",
        "- Mistral / Mixtral  \n",
        "- Falcon  \n",
        "- GPT-J / GPT-NeoX  \n",
        "- Gemma  \n",
        "- Yi Series  \n",
        "- Qwen / Qwen2  \n",
        "- Phi / Phi-3  \n",
        "- StarCoder / CodeGen / CodeLLaMA  \n",
        "- OpenHermes / Nous Hermes  \n",
        "- WizardLM / WizardCoder  \n",
        "- OPT  \n",
        "- BLOOM / BLOOMZ (BigScience)\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Text Models (Classical NLP)\n",
        "\n",
        "- BERT  \n",
        "- RoBERTa  \n",
        "- DistilBERT  \n",
        "- ALBERT  \n",
        "- ELECTRA  \n",
        "- DeBERTa  \n",
        "- T5 / Flan-T5  \n",
        "- mT5  \n",
        "- XLNet  \n",
        "- Longformer / BigBird  \n",
        "- GPT-2\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Embedding Models\n",
        "\n",
        "- Sentence-BERT (SBERT)  \n",
        "- all-MiniLM-L6-v2  \n",
        "- Instructor-XL / Instructor-L  \n",
        "- E5 / E5-Mistral  \n",
        "- Jina Embeddings  \n",
        "- Voyage Embeddings (open variants)\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Vision Models (CV)\n",
        "\n",
        "- ViT (Vision Transformer)  \n",
        "- ResNet  \n",
        "- ConvNeXt  \n",
        "- MobileNet  \n",
        "- YOLOv5 / YOLOv7 / YOLOv8 / YOLOv9  \n",
        "- DETR / Deformable DETR  \n",
        "- SAM (Segment Anything)  \n",
        "- DINO / DINOv2  \n",
        "- CLIP Vision\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Multimodal Models\n",
        "\n",
        "- CLIP (Vision + Text)  \n",
        "- Flamingo  \n",
        "- LLaVA  \n",
        "- VILA  \n",
        "- ImageBind  \n",
        "- Kosmos-2  \n",
        "- InternVL\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Diffusion and Image Generation\n",
        "\n",
        "- Stable Diffusion 1.5  \n",
        "- Stable Diffusion 2.1  \n",
        "- Stable Diffusion XL (SDXL)  \n",
        "- PixArt-Alpha / PixArt-Sigma  \n",
        "- Stable Cascade  \n",
        "- Diffusers UNet models  \n",
        "- Kandinsky  \n",
        "- DeepFloyd-IF  \n",
        "- ControlNet  \n",
        "- AnimateDiff  \n",
        "- Stable Video Diffusion  \n",
        "- Runway Gen-1 / Gen-2 (open demos)\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Audio / Speech Models\n",
        "\n",
        "### Speech-to-Text\n",
        "- Whisper (OpenAI)  \n",
        "- Wav2Vec2  \n",
        "- MMS (Meta Massively Multilingual Speech)\n",
        "\n",
        "### Text-to-Speech\n",
        "- Bark  \n",
        "- XTTS-v2  \n",
        "- FastSpeech2  \n",
        "- VITS\n",
        "\n",
        "### Audio Classification\n",
        "- YAMNet  \n",
        "- Audio Spectrogram Transformer (AST)\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Video Models\n",
        "\n",
        "- Stable Video Diffusion  \n",
        "- Video Composer  \n",
        "- OpenSora  \n",
        "- Lumiere (research re-implementations)  \n",
        "- AnimateDiff video pipelines\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Reinforcement Learning / Control\n",
        "\n",
        "- Decision Transformer  \n",
        "- Dreamer  \n",
        "- PPO / SAC pretrained agents\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Tokenizers and Feature Extractors\n",
        "\n",
        "- SentencePiece  \n",
        "- Hugging Face Tokenizers  \n",
        "- BPE / WordPiece vocab files\n",
        "\n",
        "---\n",
        "\n",
        "# HUGGING FACE SPACES (GRADIO / STREAMLIT)\n",
        "\n",
        "Spaces are hosted applications â€” not models.\n",
        "\n",
        "---\n",
        "\n",
        "## Types of Spaces\n",
        "\n",
        "- Gradio Apps  \n",
        "- Streamlit Apps  \n",
        "- Docker Spaces  \n",
        "- Static HTML Spaces\n",
        "\n",
        "---\n",
        "\n",
        "## Popular Categories of Spaces\n",
        "\n",
        "### Model Demos\n",
        "Interactive demos for:  \n",
        "- LLM chatbots  \n",
        "- Stable Diffusion generators  \n",
        "- SAM segmentation  \n",
        "- CLIP retrieval  \n",
        "\n",
        "### Data Science Tools\n",
        "- CSV explorers  \n",
        "- Embedding search  \n",
        "- Model evaluation dashboards  \n",
        "\n",
        "### Educational Labs\n",
        "- Transformer visualizers  \n",
        "- Attention heads explorer  \n",
        "- RL simulators  \n",
        "\n",
        "### AI Agents\n",
        "- AutoGPT demos  \n",
        "- LangChain apps  \n",
        "- CrewAI task automation apps  \n",
        "\n",
        "### Enterprise Tools\n",
        "- Document Q&A with RAG  \n",
        "- Vector search frontends  \n"
      ],
      "metadata": {
        "id": "28lD2rRDYSLQ"
      }
    }
  ]
}